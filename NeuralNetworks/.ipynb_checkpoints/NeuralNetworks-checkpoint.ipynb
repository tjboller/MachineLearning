{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NeuralNetworks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TJ\\Anaconda\\lib\\site-packages\\matplotlib\\__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import io, special, optimize\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    '''\n",
    "        Defines a class structure for handling nueral networks\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,num_units_per_layer = [], weights = [], regularization = 0):\n",
    "        \n",
    "        # Define the activation function using sigmoid here\n",
    "        self.__act_func = special.expit\n",
    "        \n",
    "        self.regularization = regularization\n",
    "        \n",
    "        # If thetas are not provided set random thetas and \n",
    "        # set the skeleton for the neural network, ie\n",
    "        # the number of hidden layers and units per layer must\n",
    "        # be provided\n",
    "        if len(weights) == 0:\n",
    "\n",
    "            if len(num_units_per_layer) < 0:\n",
    "                raise NameError('Must set (list) num_units_per_layer if weights not provided')\n",
    "            \n",
    "            # Number of hidden layers, not including input or output\n",
    "            self.num_hidden_layers = len(num_units_per_layer)-2\n",
    "\n",
    "            # List of number of neurons in each layer, including input and output\n",
    "            self.num_units_per_layer = num_units_per_layer\n",
    "    \n",
    "            # Set random weights\n",
    "            self.weights = self.__init__weights()\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # Set weights and number of hidden layers\n",
    "            self.weights = weights\n",
    "            self.num_hidden_layers = len(self.weights) - 1\n",
    "            self.num_units_per_layer = [400,25,10]\n",
    "        \n",
    "    def __init__weights(self):\n",
    "        '''set random thetas'''\n",
    "        \n",
    "        thetas = []\n",
    "        for i in range(self.num_hidden_layers + 1):\n",
    "            \n",
    "            # Set n to be the image of the transformation, \n",
    "            # m to be the dimension of the input vector\n",
    "            n = self.num_units_per_layer[i+1]\n",
    "            m = self.num_units_per_layer[i] + 1\n",
    "            \n",
    "            # Define the epsilon which for which all elements in the \n",
    "            # random matrix are in [-epsilon, epsilon]\n",
    "            epsilon = np.sqrt(6)/np.sqrt(n+m)\n",
    "            thetas.append(np.random.rand(n,m) * 2 * epsilon - epsilon)\n",
    "            \n",
    "        return thetas\n",
    "    \n",
    "    \n",
    "    # given input of a list a matrices, returns all matrices as a 1-D vector, used in optimization\n",
    "    def __concat(self,matrix_list):\n",
    "        unrolled = matrix_list[0].ravel()\n",
    "        for i in range(1,len(matrix_list)):\n",
    "            unrolled = np.insert(unrolled,len(unrolled),matrix_list[i].ravel())\n",
    "        return unrolled\n",
    "\n",
    "\n",
    "    # rebuilds a 1-D vector into the list of matrices that can be used in computation\n",
    "    def __rebuild_matrices(self, matrix_vec):\n",
    "        \n",
    "        # nxm values for first layer\n",
    "        n = self.num_units_per_layer[1]\n",
    "        m = self.num_units_per_layer[0] + 1\n",
    "\n",
    "        lower_bound = 0\n",
    "        upper_bound = n*m\n",
    "        matrices = []\n",
    "\n",
    "        \n",
    "        for layer in range(1, len(self.num_units_per_layer)):\n",
    "        \n",
    "            # get rebuilt matrix for layer\n",
    "            matrices.append(matrix_vec[lower_bound:upper_bound].reshape((n,m)))\n",
    "\n",
    "            # if all matrices havent been updated, update the parameters\n",
    "            if layer < len(self.num_units_per_layer) -1 :\n",
    "                n = self.num_units_per_layer[layer + 1]\n",
    "                m = self.num_units_per_layer[layer] + 1\n",
    "\n",
    "                lower_bound = upper_bound\n",
    "                upper_bound += n*m\n",
    "\n",
    "        return matrices\n",
    "    \n",
    "    \n",
    "    def get_activations(self, input_vec, weights = []):\n",
    "        ''' \n",
    "            returns a list of all the activations, takes up more memory then recursion but the \n",
    "            intermediate values are used for backprop\n",
    "            \n",
    "            input_vec -> array - values of input layer\n",
    "            weights -> list of the weights\n",
    "        '''\n",
    "        \n",
    "        # if weights is empty, then its used for testing\n",
    "        if len(weights) == 0:\n",
    "            weights = self.weights\n",
    "        \n",
    "        \n",
    "        # Add bais unit to first input layer\n",
    "        input_vec = np.insert(input_vec,0,1)\n",
    "        activations = [input_vec]\n",
    "        \n",
    "\n",
    "        for depth in range(self.num_hidden_layers + 1):\n",
    "            \n",
    "            # The next layer is the activation function applied to the weights * current activation\n",
    "            next_activation = self.__act_func(weights[depth].dot(activations[-1]))\n",
    "            \n",
    "            # Add a bais unit if the layer isn't the output layer\n",
    "            if depth != self.num_hidden_layers:\n",
    "                next_activation = np.insert(next_activation,0,1)\n",
    "                \n",
    "            activations.append(next_activation)\n",
    "            \n",
    "        return activations\n",
    "    \n",
    "    def predict(self, input_vec, weights = [], categorize = False):\n",
    "        '''Get prediction for an input vector and weights'''\n",
    "        \n",
    "        if len(weights) == 0:\n",
    "            weights = self.weights\n",
    "        \n",
    "        # the prediction is the last activation layer\n",
    "        prediction = self.get_activations(input_vec, weights)[-1]\n",
    "        \n",
    "        # return the index of the highest probability if \n",
    "        # we want to categorize the output\n",
    "        if categorize:\n",
    "            return np.argmax(prediction) + 1\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "    def predict_set(self, examples, weights = [], categorize = False):\n",
    "        '''Predicts a set a examples'''\n",
    "    \n",
    "        if len(weights) == 0:\n",
    "            weights = self.weights\n",
    "        \n",
    "        predictions = []\n",
    "        for example in examples:\n",
    "            predictions.append(self.predict(example, weights, categorize))\n",
    "    \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def __training_cost(self, training, answers, weights):\n",
    "        '''Returns cost of training set'''\n",
    "        \n",
    "        cost = 0\n",
    "        for example, answer in zip(training,answers):\n",
    "            \n",
    "            # get prediction\n",
    "            output = self.predict(example, weights)\n",
    "            \n",
    "            # calculate cost of example\n",
    "            cost += sum(-answer * np.log(output) - (1 - answer) * np.log(1-output))\n",
    "        \n",
    "        # return cost if no regularization\n",
    "        if self.regularization == 0:\n",
    "            return (1/len(training)) * cost\n",
    "\n",
    "        # calculate regularization\n",
    "        else:\n",
    "            reg = 0\n",
    "            for weight in weights:\n",
    "                weight[:,0] = 0 # don't include bais units\n",
    "                reg += sum(weight.ravel()**2)\n",
    "\n",
    "            # return cost\n",
    "            return (1/len(training)) * (cost + (self.regularization/2)*reg)\n",
    "                       \n",
    "            \n",
    "    def back_prop(self, training, answers, weights):\n",
    "        '''train neural network using back propagation'''\n",
    "        \n",
    "        # initalize culumative deltas and gradients\n",
    "        clm_deltas = []\n",
    "        gradients = []\n",
    "        for weight in weights:\n",
    "            clm_deltas.append(np.zeros(weight.shape))\n",
    "        \n",
    "        # for each training example and answer, do the back prop alg\n",
    "        for example, answer in zip(training, answers):\n",
    "            \n",
    "            # get the activations for the input example\n",
    "            activations = self.get_activations(example, weights)\n",
    "            \n",
    "            # get deltas for each layer\n",
    "            deltas = []\n",
    "            deltas.append(activations[-1] - answer)\n",
    "            for layer in range(self.num_hidden_layers,0,-1):\n",
    "                delta = weights[layer].T.dot(deltas[-1]) * activations[layer] * (1 - activations[layer])\n",
    "                deltas.append( delta[1:] )\n",
    "            \n",
    "            # we defined the deltas backwards (easier to compute) so we have to reverse the list\n",
    "            deltas.reverse()\n",
    "            \n",
    "            # accumulate the deltas for each layer\n",
    "            for layer in range(self.num_hidden_layers+1):\n",
    "                _delta = deltas[layer].reshape(-1,1)\n",
    "                _activ = activations[layer].reshape(-1,1)                \n",
    "                clm_deltas[layer] = clm_deltas[layer] + _delta.dot(_activ.T)\n",
    "        \n",
    "        # divide by num examples and add regularization cost\n",
    "        for layer in range(self.num_hidden_layers+1):\n",
    "            reg_weight = np.copy(weights[layer])\n",
    "            reg_weight[:,0] = 0\n",
    "            gradients.append(\n",
    "                (1/len(training)) * (clm_deltas[layer] + self.regularization * reg_weight))\n",
    "        \n",
    "        return self.__concat(gradients)\n",
    "    \n",
    "    def train(self,training, answers):\n",
    "        \n",
    "        # define wrappers for functions for use of the optimizer\n",
    "        def _cost(weights_vec):\n",
    "            weights = self.__rebuild_matrices(weights_vec)\n",
    "            return self.__training_cost(training, answers, weights)\n",
    "        \n",
    "        def _back_prop(weights_vec):\n",
    "            weights = self.__rebuild_matrices(weights_vec)\n",
    "            return self.back_prop(training, answers, weights)\n",
    "        \n",
    "        # return optimized weights\n",
    "        f0 = self.__concat(self.weights)\n",
    "        return optimize.fmin_cg(_cost, f0, fprime= _back_prop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _back_prop(weights_vec):\n",
    "    return model.back_prop(training, answers,weights)\n",
    "def _cost(weights_vec):\n",
    "    return model.training_cost(training, answers, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = io.loadmat('ex4data1.mat')\n",
    "weights = io.loadmat('ex4weights.mat')\n",
    "weights = [weights['Theta1'], weights['Theta2']]\n",
    "\n",
    "weights_vec = weights[0].ravel()\n",
    "for i in range(1,len(weights)):\n",
    "    weights_vec = np.insert(weights_vec,len(weights_vec),weights[i].ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = data['X']\n",
    "answers = data['y']\n",
    "answers = np.concatenate(answers)\n",
    "new_answers = []\n",
    "for answer in answers:\n",
    "    _element = np.zeros(10)\n",
    "    _element[(answer+9)%10] = 1\n",
    "    new_answers.append(_element)\n",
    "    \n",
    "answers = new_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork(num_units_per_layer=[400,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5573189952011837"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f0 = unroll(model.weights)\n",
    "optimize.check_grad(_cost, _back_prop, f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
